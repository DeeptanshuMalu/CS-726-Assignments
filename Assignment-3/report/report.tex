\documentclass[11pt]{article}

% Packages
\usepackage[margin=1in, top=0.7in]{geometry}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\graphicspath{{./}{../}}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{multirow}

% Document info
\title{Assignment 3 Report\\
    CS-726: Advanced Machine Learning}
\author{Deeptanshu Malu \quad Deevyanshu Malu \quad Neel Rambhia}
\date{}

\begin{document}

\maketitle

\section{Task 0}
\begin{longtable}{|l|c|c|c|c|}
    \hline
    \textbf{Decoding Strategy} & \textbf{BLEU} & \textbf{ROUGE-1} & \textbf{ROUGE-2} & \textbf{ROUGE-LCS} \\
    \hline
    Greedy & \textbf{0.3097} & \textbf{0.3538} & \textbf{0.1297} & \textbf{0.2704} \\
    \hline
    Random (temp=0.5) & 0.2856 & 0.2929 & 0.1113 & 0.2387 \\
    \hline
    Random (temp=0.9) & 0.1996 & 0.1791 & 0.0550 & 0.1477 \\
    \hline
    Top-k (k=5) & 0.2388 & 0.2230 & 0.0607 & 0.1715 \\
    \hline
    Top-k (k=10) & 0.2427 & 0.2491 & 0.0799 & 0.2004 \\
    \hline
    Nucleus Sampling (p=0.5) & 0.2706 & 0.2554 & 0.0905 & 0.1973 \\
    \hline
    Nucleus Sampling (p=0.9) & 0.1957 & 0.1883 & 0.0469 & 0.1329 \\
    \hline
    \caption{Evaluation metrics for different decoding strategies.}
\end{longtable}

Greedy decoding performs best across all metrics. On adding more randomness (higher temperature or larger sampling pools), the performance gets worse. Among sampling methods, Random with temperature=0.5 and Nucleus Sampling with p=0.5 work better than others. This tells us that some randomness can help, but too much hurts performance.

\section{Task 1}
The model used is \texttt{meta-llama/Llama-2-7b-chat-hf}.

We implemented constrained decoding using a trie data structure to limit the model's output to a predefined vocabulary. The algorithm selects the highest probability token that is valid according to the trie at each step.

\begin{algorithm}
\caption{Constrained Decoding using Trie}
\begin{algorithmic}[1]
\State Build trie from target vocabulary (word list)
\State Add EOS token to trie
\State $node \gets trie.root$
\For{$i = 1$ to $max\_output\_length$}
    \State Compute logits for the last token in the sequence
    \State Convert logits to probabilities using softmax
    \State Sort probabilities in descending order
    \For{each token $t$ in sorted order}
        \If{$t$ is a child of current $node$}
            \State Select $t$ as the next token
            \State $node \gets node.children[t]$
            \If{$node$ has no children} \Comment{Can be replaced with $node.is\_end$ condition}
                        \State $node \gets trie.root$ \Comment{Reset trie state}
                    \EndIf
            \State \textbf{break}
        \EndIf
    \EndFor
    \State Append selected token to the output sequence
    \If{selected token is EOS}
        \State \textbf{break}
    \EndIf
\EndFor
\State \textbf{return} generated sequence
\end{algorithmic}
\end{algorithm}

We tested two trie traversal strategies: resetting the trie when reaching an end node (is\_end) and resetting when a node has no children. The second strategy performed slightly better, as shown in the results table below.

\begin{longtable}{|l|c|c|c|c|}
    \hline
    \textbf{Strategy} & \textbf{BLEU} & \textbf{ROUGE-1} & \textbf{ROUGE-2} & \textbf{ROUGE-LCS} \\
    \hline
    Regular greedy & 0.2781 & 0.3351 & 0.1230 & 0.2640 \\
    \hline
    Reset when is\_end & 0.5111 & 0.5270 & 0.3189 & \textbf{0.4694} \\
    \hline
    Reset when no children & \textbf{0.5116} & \textbf{0.5307} & \textbf{0.3205} & 0.4675 \\
    \hline
    \caption{Evaluation metrics for constrained decoding strategies.}
\end{longtable}



\section*{Contributions}

\begin{itemize}
    \item \textbf{Deeptanshu Malu}:
    \begin{enumerate}
        \item 
    \end{enumerate}

    \item \textbf{Deevyanshu Malu}:
    \begin{enumerate}
        \item 
    \end{enumerate}

    \item \textbf{Neel Rambhia}:
    \begin{enumerate}
        \item 
    \end{enumerate}
\end{itemize}

\section*{Acknowledgements}

\begin{itemize}
    \item 
\end{itemize}


\end{document}