\documentclass[11pt]{article}

% Packages
\usepackage[margin=1in, top=0.7in]{geometry}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\graphicspath{{./}{../}}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{multirow}

% Document info
\title{Assignment 3 Report\\
    CS-726: Advanced Machine Learning}
\author{Deeptanshu Malu \quad Deevyanshu Malu \quad Neel Rambhia}
\date{}

\begin{document}

\maketitle

\section{Task 0}
\begin{longtable}{|l|c|c|c|c|}
    \hline
    \textbf{Decoding Strategy} & \textbf{BLEU} & \textbf{ROUGE-1} & \textbf{ROUGE-2} & \textbf{ROUGE-LCS} \\
    \hline
    Greedy & \textbf{0.3097} & \textbf{0.3538} & \textbf{0.1297} & \textbf{0.2704} \\
    \hline
    Random (temp=0.5) & 0.2856 & 0.2929 & 0.1113 & 0.2387 \\
    \hline
    Random (temp=0.9) & 0.1996 & 0.1791 & 0.0550 & 0.1477 \\
    \hline
    Top-k (k=5) & 0.2388 & 0.2230 & 0.0607 & 0.1715 \\
    \hline
    Top-k (k=10) & 0.2427 & 0.2491 & 0.0799 & 0.2004 \\
    \hline
    Nucleus Sampling (p=0.5) & 0.2706 & 0.2554 & 0.0905 & 0.1973 \\
    \hline
    Nucleus Sampling (p=0.9) & 0.1957 & 0.1883 & 0.0469 & 0.1329 \\
    \hline
    \caption{Evaluation metrics for different decoding strategies.}
\end{longtable}

Greedy decoding performs best across all metrics. On adding more randomness (higher temperature or larger sampling pools), the performance gets worse. Among sampling methods, Random with temperature=0.5 and Nucleus Sampling with p=0.5 work better than others. This tells us that some randomness can help, but too much hurts performance.

\section{Task 1}
The model used is \texttt{meta-llama/Llama-2-7b-chat-hf}.

We implemented constrained decoding using a trie data structure to limit the model's output to a predefined vocabulary. The algorithm selects the highest probability token that is valid according to the trie at each step.

\begin{algorithm}
\caption{Constrained Decoding using Trie}
\begin{algorithmic}[1]
\State Build trie from target vocabulary (word list)
\State Add EOS token to trie
\State $node \gets trie.root$
\For{$i = 1$ to $max\_output\_length$}
    \State Compute logits for the last token in the sequence
    \State Convert logits to probabilities using softmax
    \State Sort probabilities in descending order
    \For{each token $t$ in sorted order}
        \If{$t$ is a child of current $node$}
            \State Select $t$ as the next token
            \State $node \gets node.children[t]$
            \If{$node$ has no children} \Comment{Can be replaced with $node.is\_end$ condition}
                        \State $node \gets trie.root$ \Comment{Reset trie state}
                    \EndIf
            \State \textbf{break}
        \EndIf
    \EndFor
    \State Append selected token to the output sequence
    \If{selected token is EOS}
        \State \textbf{break}
    \EndIf
\EndFor
\State \textbf{return} generated sequence
\end{algorithmic}
\end{algorithm}

We tested two trie traversal strategies: resetting the trie when reaching an end node (is\_end) and resetting when a node has no children. The second strategy performed slightly better, as shown in the results table below.

\begin{longtable}{|l|c|c|c|c|}
    \hline
    \textbf{Strategy} & \textbf{BLEU} & \textbf{ROUGE-1} & \textbf{ROUGE-2} & \textbf{ROUGE-LCS} \\
    \hline
    Regular greedy & 0.2781 & 0.3351 & 0.1230 & 0.2640 \\
    \hline
    Reset when is\_end & 0.5111 & 0.5270 & 0.3189 & \textbf{0.4694} \\
    \hline
    Reset when no children & \textbf{0.5116} & \textbf{0.5307} & \textbf{0.3205} & 0.4675 \\
    \hline
    \caption{Evaluation metrics for constrained decoding strategies.}
\end{longtable}

\section{Task 2}
The model used is \texttt{FasterDecoding/medusa-v1.0-vicuna-7b-v1.5}.
The results for different beam widths (W) and numbers of Medusa heads (S) are shown below:

\begin{longtable}{|c|c|c|c|c|c|c|}
    \hline
    \textbf{W} & \textbf{S} & \textbf{BLEU} & \textbf{ROUGE-1} & \textbf{ROUGE-2} & \textbf{ROUGE-LCS} & \textbf{RTF} \\
    \hline
    2 & 2 & \textbf{0.1294} & \textbf{0.1174} & \textbf{0.0192} & \textbf{0.0987} & 0.0207 \\
    \hline
    5 & 2 & 0.0912 & 0.0970 & 0.0168 & 0.0782 & 0.0221 \\
    \hline
    10 & 2 & 0.0510 & 0.0822 & 0.0122 & 0.0612 & 0.0252 \\
    \hline
    2 & 5 & 0.0550 & 0.0794 & 0.0053 & 0.0721 & 0.0278 \\
    \hline
    5 & 5 & 0.0261 & 0.0522 & 0.0042 & 0.0457 & \textbf{0.0148} \\
    \hline
    10 & 5 & 0.0005 & 0.0169 & 0.0000 & 0.0149 & 0.0253 \\
    \hline
    \caption{Evaluation metrics for Medusa with different beam widths and head counts.}
\end{longtable}

The best performance was achieved with the smallest beam width (W=2) and fewest heads (S=2). As we increased beam width or number of heads, performance declined across all metrics. This suggests that for this specific task, simpler configurations work better. The configuration with W=5 and S=5 achieved the best real-time factor (RTF), indicating faster decoding, but at a significant cost to generation quality.

\section*{Contributions}

\begin{itemize}
    \item \textbf{Deeptanshu Malu}:
    \begin{enumerate}
        \item 
    \end{enumerate}

    \item \textbf{Deevyanshu Malu}:
    \begin{enumerate}
        \item 
    \end{enumerate}

    \item \textbf{Neel Rambhia}:
    \begin{enumerate}
        \item 
    \end{enumerate}
\end{itemize}

\section*{Acknowledgements}

\begin{itemize}
    \item We have also used Copilot for faster coding and not for direct logic.
\end{itemize}


\end{document}