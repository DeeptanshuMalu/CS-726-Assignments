\documentclass[11pt]{article}

% Packages
\usepackage[margin=1in, top=0.7in]{geometry}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\graphicspath{{./}{../}}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{multirow}

% Document info
\title{Assignment 3 Report\\
    CS-726: Advanced Machine Learning}
\author{Deeptanshu Malu \quad Deevyanshu Malu \quad Neel Rambhia}
\date{}

\begin{document}

\maketitle

\section{Task 0}

The model used is \texttt{meta-llama/Llama-2-7b-hf}.

\begin{longtable}{|l|c|c|c|c|}
    \hline
    \textbf{Decoding Strategy} & \textbf{BLEU} (↑) & \textbf{ROUGE-1} (↑) & \textbf{ROUGE-2} (↑) & \textbf{ROUGE-LCS} (↑) \\
    \hline
    Greedy & \textbf{0.3097} & \textbf{0.3538} & \textbf{0.1297} & \textbf{0.2704} \\
    \hline
    Random (temp=0.5) & 0.2856 & 0.2929 & 0.1113 & 0.2387 \\
    \hline
    Random (temp=0.9) & 0.1996 & 0.1791 & 0.0550 & 0.1477 \\
    \hline
    Top-k (k=5) & 0.2388 & 0.2230 & 0.0607 & 0.1715 \\
    \hline
    Top-k (k=10) & 0.2427 & 0.2491 & 0.0799 & 0.2004 \\
    \hline
    Nucleus Sampling (p=0.5) & 0.2706 & 0.2554 & 0.0905 & 0.1973 \\
    \hline
    Nucleus Sampling (p=0.9) & 0.1957 & 0.1883 & 0.0469 & 0.1329 \\
    \hline
    \caption{Evaluation metrics for different decoding strategies.}
\end{longtable}

Greedy decoding performs best across all metrics. On adding more randomness (higher temperature or larger sampling pools), the performance gets worse. Among sampling methods, Random with temperature=0.5 and Nucleus Sampling with p=0.5 work better than others. This tells us that some randomness can help, but too much hurts performance.

\section{Task 1}
The model used is \texttt{meta-llama/Llama-2-7b-chat-hf}.

We implemented constrained decoding using a trie data structure to limit the model's output to a predefined vocabulary. The trie is created by first tokenizing the target vocabulary and then inserting each token into the trie. We have also added the end-of-sequence (EOS) token to the root of the trie. The algorithm selects the highest probability token that is valid according to the trie at each step.

\begin{algorithm}
\caption{Constrained Decoding using Trie}
\begin{algorithmic}[1]
\State Build trie from target vocabulary (word list)
\State Add EOS token to trie
\State $node \gets trie.root$
\For{$i = 1$ to $max\_output\_length$}
    \State Compute logits for the last token in the sequence
    \State Convert logits to probabilities using softmax
    \State Sort probabilities in descending order
    \For{each token $t$ in sorted order}
        \If{$t$ is a child of current $node$}
            \State Select $t$ as the next token
            \State $node \gets node.children[t]$
            \If{$node$ has no children} \Comment{Can be replaced with $node.is\_end$ condition}
                        \State $node \gets trie.root$ \Comment{Reset trie state}
                    \EndIf
            \State \textbf{break}
        \EndIf
    \EndFor
    \State Append selected token to the output sequence
    \If{selected token is EOS}
        \State \textbf{break}
    \EndIf
\EndFor
\State \textbf{return} generated sequence
\end{algorithmic}
\end{algorithm}

We tested two trie traversal strategies: resetting the trie traversal when reaching an end node (is\_end) and resetting when a node has no children. The second strategy performed slightly better, as shown in the results table below.

\begin{longtable}{|l|c|c|c|c|}
    \hline
    \textbf{Decoding Strategy} & \textbf{BLEU} (↑) & \textbf{ROUGE-1} (↑) & \textbf{ROUGE-2} (↑) & \textbf{ROUGE-LCS} (↑) \\
    \hline
    Regular greedy & 0.2781 & 0.3351 & 0.1230 & 0.2640 \\
    \hline
    Reset when is\_end & 0.5111 & 0.5270 & 0.3189 & \textbf{0.4694} \\
    \hline
    Reset when no children & \textbf{0.5116} & \textbf{0.5307} & \textbf{0.3205} & 0.4675 \\
    \hline
    \caption{Evaluation metrics for constrained decoding strategies.}
\end{longtable}

\section{Task 2}
The model used is \texttt{FasterDecoding/medusa-v1.0-vicuna-7b-v1.5}.

\subsection{Single-head decoding}
For single-head Medusa decoding, we evaluated the model using greedy decoding strategy:

\begin{longtable}{|c|c|c|c|c|}
    \hline
    \textbf{BLEU} & \textbf{ROUGE-1} & \textbf{ROUGE-2} & \textbf{ROUGE-LCS} & \textbf{RTF} \\
    \hline
    0.2921 & 0.3963 & 0.1483 & 0.3177 & 0.0573 \\
    \hline
    \caption{Evaluation metrics for single-head Medusa decoding.}
\end{longtable}

\subsection{Multi-head decoding}
When the EOS token appears at the end of a candidate sequence then we don't append any more tokens to it.
The results for different beam widths (W) and numbers of Medusa heads (S) are shown below:

\begin{longtable}{|c|c|c|c|c|c|c|}
    \hline
    \textbf{W} & \textbf{S} & \textbf{BLEU} (↑) & \textbf{ROUGE-1} (↑) & \textbf{ROUGE-2} (↑) & \textbf{ROUGE-LCS} (↑) & \textbf{RTF} (↓) \\
    \hline
        2 & 2 & 0.1595 & 0.1700 & 0.0324 & 0.1429 & 0.0581 \\
        \hline
        5 & 2 & 0.1849 & 0.1767 & 0.0433 & 0.1382 & 0.1288 \\
        \hline
        10 & 2 & \textbf{0.2788} & \textbf{0.2375} & \textbf{0.0695} & \textbf{0.1822} & 0.2396 \\
        \hline
        2 & 5 & 0.0760 & 0.0965 & 0.0066 & 0.0827 & \textbf{0.0345} \\
        \hline
        5 & 5 & 0.0425 & 0.0799 & 0.0138 & 0.0682 & 0.0714 \\
        \hline
        10 & 5 & 0.0077 & 0.0250 & 0.0017 & 0.0219 & 0.1691 \\
        \hline
    \caption{Evaluation metrics for multi-head Medusa decoding with different beam widths and number of heads.}
\end{longtable}

Key observations from the multi-head decoding results:
\begin{itemize}
    \item The best performance was achieved with W=10 and S=2.
    \item Increasing the number of heads (S) did not improve performance, and in fact, hurt it.
    \item When the number of heads was 2, the BLEU and ROUGE scores improved with increasing beam width.
    \item When the number of heads was increased to 5, the BLEU and ROUGE scores dropped with increasing beam width.
    \item With constant number of Medusa heads, increasing beam width increased the RTF.
    \item With constant beam width, increasing the number of Medusa heads decreased the RTF.
\end{itemize}

\section*{Contributions}

\begin{itemize}
    \item \textbf{Deeptanshu Malu}:
    \begin{enumerate}
        \item Formulated the trie data structure design for Task 1.
        \item Coded the multi head decoding algorithm for Task 2.
    \end{enumerate}

    \item \textbf{Deevyanshu Malu}:
    \begin{enumerate}
        \item Coded the trie data structure and the constrained decoding algorithm for Task 1.
        \item Coded the multi head decoding algorithm for Task 2.
    \end{enumerate}

    \item \textbf{Neel Rambhia}:
    \begin{enumerate}
        \item Completed all decoding algorithms in Task 0.
        \item Coded the single head decoding algorithm for Task 2.
    \end{enumerate}
\end{itemize}

\section*{Acknowledgements}

\begin{itemize}
    \item We have also used Copilot for faster coding and not for direct logic.
    \item Used ChatGPT to generate the trie data structure but filled in the logic ourselves.
\end{itemize}


\end{document}